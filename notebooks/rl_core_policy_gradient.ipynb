{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Install packages"
      ],
      "metadata": {
        "id": "m2GNCpOMht1r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DcTQgCGXhihn"
      },
      "outputs": [],
      "source": [
        "!pip install -q gymnasium[classic-control]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import and create cartpole"
      ],
      "metadata": {
        "id": "265S31XOhxFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "env = gym.make(\"CartPole-v1\")\n",
        "obs, info = env.reset(seed=0)\n",
        "\n",
        "print(\"Obs shape:\", obs.shape)\n",
        "print(\"Action space:\", env.action_space)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXkeuB4JhtFm",
        "outputId": "05ca3af2-3b3d-434c-9f74-80eccb452b88"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obs shape: (4,)\n",
            "Action space: Discrete(2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rendering in Colab"
      ],
      "metadata": {
        "id": "AtY0DgMKh1w0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
        "obs, info = env.reset()\n",
        "\n",
        "frame = env.render()\n",
        "plt.imshow(frame)\n",
        "plt.axis(\"off\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "ahXLBH8Ihy1e",
        "outputId": "b2aa7cb7-179e-491d-da0d-c371e6e0a147"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(np.float64(-0.5), np.float64(599.5), np.float64(399.5), np.float64(-0.5))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 0\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "env.reset(seed=seed)\n",
        "env.action_space.seed(seed)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxfr4tPKh3Az",
        "outputId": "0c8859fa-c061-458e-f42e-463501a7bcbe"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## REINFORCE"
      ],
      "metadata": {
        "id": "2IjZLMmJiBs8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PolicyNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(4, 128)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.fc2 = nn.Linear(128, 2)\n",
        "    self.stack = nn.Sequential(self.fc1, self.relu, self.fc2)\n",
        "  def forward(self, x):\n",
        "    x =  self.stack(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "uHvnBHvuh_Ag"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.distributions import Categorical\n",
        "\n",
        "def run_episode(env, initial_state, model, max_steps: int) :\n",
        "  state = initial_state\n",
        "  log_probs = []\n",
        "  rewards = []\n",
        "  for t in range(max_steps):\n",
        "    action_probs = model(torch.tensor(state, dtype=torch.float32))\n",
        "    dist = Categorical(logits = action_probs)\n",
        "    action = dist.sample()\n",
        "    log_prob = dist.log_prob(action)\n",
        "\n",
        "    next_state, reward, terminated, truncated, _ = env.step(action.item())\n",
        "\n",
        "    log_probs.append(log_prob)\n",
        "    rewards.append(reward)\n",
        "    state = next_state\n",
        "    if terminated or truncated:\n",
        "      break\n",
        "  return log_probs, rewards\n",
        "\n",
        "def get_expected_return (rewards, gamma, standardize):\n",
        "  G = 0.0\n",
        "  returns = []\n",
        "  for r in reversed(rewards):\n",
        "      G = r + gamma * G\n",
        "      returns.append(G)\n",
        "  returns.reverse()\n",
        "  returns = torch.tensor(returns, dtype=torch.float32)\n",
        "\n",
        "  if len(returns) > 1:\n",
        "      returns = (returns - returns.mean()) / (returns.std() + 1e-8)\n",
        "  return returns\n"
      ],
      "metadata": {
        "id": "otEWGcZJlwsw"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "env = gym.make(\"CartPole-v1\")\n",
        "model = PolicyNetwork()\n",
        "optimizer = optim.Adam(model.parameters() , lr = 1e-2)\n",
        "\n",
        "gamma = 0.99\n",
        "beta = 0.01\n",
        "episode_returns = []\n",
        "\n",
        "\n",
        "for ep in range(1000) :\n",
        "  obs, info = env.reset(seed = None)\n",
        "  log_probs, rewards = run_episode(env, obs, model, max_steps = 500)\n",
        "\n",
        "  returns = get_expected_return(rewards, gamma, standardize = True)\n",
        "  log_probs = torch.stack(log_probs)\n",
        "\n",
        "  loss = -(log_probs * returns).sum()\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  ep_ret = float(sum(rewards))\n",
        "  episode_returns.append(ep_ret)\n",
        "  avg100 = np.mean(episode_returns[-100:])\n",
        "  if (ep + 1) % 10 == 0:\n",
        "    print(f\"ep {ep+1:4d} | return {ep_ret:6.1f} | avg100 {avg100:6.1f} | loss {loss.item():8.3f}\")\n",
        "\n",
        "  if avg100 >= 475:\n",
        "    print(\"Solved CartPole-v1.\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQuE9oS10mD4",
        "outputId": "acc09e83-a1ba-444d-aace-cd5e3e6b94ac"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep   10 | return   48.0 | avg100   32.7 | loss   -1.650\n",
            "ep   20 | return   57.0 | avg100   42.6 | loss   -0.301\n",
            "ep   30 | return   42.0 | avg100   57.4 | loss   -1.184\n",
            "ep   40 | return   95.0 | avg100   64.2 | loss   -0.999\n",
            "ep   50 | return   56.0 | avg100   59.6 | loss    0.156\n",
            "ep   60 | return  130.0 | avg100   73.1 | loss    2.025\n",
            "ep   70 | return  157.0 | avg100   78.6 | loss    6.266\n",
            "ep   80 | return  251.0 | avg100   84.9 | loss    1.741\n",
            "ep   90 | return   42.0 | avg100   90.5 | loss    4.113\n",
            "ep  100 | return  257.0 | avg100   91.2 | loss    3.876\n",
            "ep  110 | return  283.0 | avg100  112.0 | loss   -4.573\n",
            "ep  120 | return  500.0 | avg100  142.2 | loss    5.195\n",
            "ep  130 | return  370.0 | avg100  172.3 | loss   -9.152\n",
            "ep  140 | return  104.0 | avg100  183.9 | loss   -4.031\n",
            "ep  150 | return   29.0 | avg100  183.1 | loss    1.486\n",
            "ep  160 | return   28.0 | avg100  172.0 | loss   -0.393\n",
            "ep  170 | return   33.0 | avg100  163.8 | loss   -0.700\n",
            "ep  180 | return   54.0 | avg100  154.6 | loss    1.437\n",
            "ep  190 | return   93.0 | avg100  147.2 | loss   -0.796\n",
            "ep  200 | return   80.0 | avg100  145.4 | loss   -2.198\n",
            "ep  210 | return   91.0 | avg100  128.9 | loss   -0.980\n",
            "ep  220 | return   70.0 | avg100   99.8 | loss   -4.733\n",
            "ep  230 | return   44.0 | avg100   66.4 | loss   -5.763\n",
            "ep  240 | return   65.0 | avg100   52.5 | loss   -4.036\n",
            "ep  250 | return   86.0 | avg100   57.0 | loss   -4.592\n",
            "ep  260 | return   52.0 | avg100   60.4 | loss   -2.274\n",
            "ep  270 | return   50.0 | avg100   63.2 | loss    0.656\n",
            "ep  280 | return   42.0 | avg100   66.1 | loss   -1.983\n",
            "ep  290 | return   56.0 | avg100   65.7 | loss   -6.529\n",
            "ep  300 | return   86.0 | avg100   64.5 | loss   -0.087\n",
            "ep  310 | return  146.0 | avg100   66.5 | loss   -6.298\n",
            "ep  320 | return   87.0 | avg100   70.4 | loss    2.717\n",
            "ep  330 | return   70.0 | avg100   72.4 | loss    3.552\n",
            "ep  340 | return   51.0 | avg100   72.7 | loss   -4.435\n",
            "ep  350 | return   43.0 | avg100   70.0 | loss   -3.161\n",
            "ep  360 | return   45.0 | avg100   68.5 | loss    0.114\n",
            "ep  370 | return   43.0 | avg100   67.0 | loss    3.773\n",
            "ep  380 | return   57.0 | avg100   66.0 | loss    4.025\n",
            "ep  390 | return   58.0 | avg100   66.7 | loss   -3.230\n",
            "ep  400 | return   79.0 | avg100   66.2 | loss   -5.014\n",
            "ep  410 | return   68.0 | avg100   63.0 | loss   -2.189\n",
            "ep  420 | return   74.0 | avg100   60.0 | loss  -14.547\n",
            "ep  430 | return  118.0 | avg100   61.3 | loss   -4.801\n",
            "ep  440 | return  322.0 | avg100   78.0 | loss   -3.657\n",
            "ep  450 | return  217.0 | avg100   90.6 | loss    2.471\n",
            "ep  460 | return  500.0 | avg100  125.7 | loss  -13.719\n",
            "ep  470 | return  450.0 | avg100  170.4 | loss   -3.318\n",
            "ep  480 | return  362.0 | avg100  200.4 | loss    1.495\n",
            "ep  490 | return  500.0 | avg100  226.3 | loss    2.590\n",
            "ep  500 | return  500.0 | avg100  270.0 | loss    2.069\n",
            "ep  510 | return  500.0 | avg100  313.6 | loss    0.421\n",
            "ep  520 | return  500.0 | avg100  356.3 | loss  -14.003\n",
            "ep  530 | return  500.0 | avg100  397.7 | loss   -3.716\n",
            "ep  540 | return  500.0 | avg100  424.5 | loss   -8.064\n",
            "ep  550 | return  500.0 | avg100  448.4 | loss   -6.577\n",
            "ep  560 | return  500.0 | avg100  454.0 | loss   -0.635\n",
            "ep  570 | return  500.0 | avg100  446.4 | loss    3.124\n",
            "ep  580 | return  500.0 | avg100  457.6 | loss   -0.058\n",
            "ep  590 | return  368.0 | avg100  469.1 | loss    2.459\n",
            "ep  600 | return   11.0 | avg100  423.8 | loss   -1.242\n",
            "ep  610 | return   10.0 | avg100  374.9 | loss   -1.673\n",
            "ep  620 | return   10.0 | avg100  325.9 | loss   -2.161\n",
            "ep  630 | return    8.0 | avg100  277.7 | loss   -3.403\n",
            "ep  640 | return   92.0 | avg100  234.5 | loss    9.258\n",
            "ep  650 | return  248.0 | avg100  208.1 | loss   -8.801\n",
            "ep  660 | return  260.0 | avg100  185.7 | loss  -19.142\n",
            "ep  670 | return  190.0 | avg100  165.1 | loss    0.650\n",
            "ep  680 | return  120.0 | avg100  137.2 | loss    3.880\n",
            "ep  690 | return  114.0 | avg100  106.0 | loss   -2.286\n",
            "ep  700 | return  164.0 | avg100  113.1 | loss    4.223\n",
            "ep  710 | return  500.0 | avg100  139.3 | loss   -5.668\n",
            "ep  720 | return  500.0 | avg100  188.3 | loss    3.228\n",
            "ep  730 | return  500.0 | avg100  235.5 | loss  -11.607\n",
            "ep  740 | return  500.0 | avg100  275.8 | loss   13.011\n",
            "ep  750 | return  500.0 | avg100  309.8 | loss    4.426\n",
            "ep  760 | return  500.0 | avg100  336.7 | loss  -12.439\n",
            "ep  770 | return  500.0 | avg100  365.9 | loss    5.149\n",
            "ep  780 | return  500.0 | avg100  397.1 | loss   13.150\n",
            "ep  790 | return  500.0 | avg100  434.4 | loss   -7.442\n",
            "ep  800 | return  500.0 | avg100  472.6 | loss    2.049\n",
            "Solved CartPole-v1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## REINFORCE + baseline"
      ],
      "metadata": {
        "id": "ek3dhXh0iDMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ValueNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.net = nn.Sequential(nn.Linear(4, 128), nn.ReLU(), nn.Linear(128, 1))\n",
        "  def forward(self, x):\n",
        "    return self.net(x).squeeze(-1)\n",
        "\n",
        "def run_episode_with_states(env, model, max_steps: int) :\n",
        "  state, info = env.reset()\n",
        "  states = []\n",
        "  log_probs = []\n",
        "  rewards = []\n",
        "  for t in range(max_steps):\n",
        "    action_probs = model(torch.tensor(state, dtype=torch.float32))\n",
        "    dist = Categorical(logits = action_probs)\n",
        "    action = dist.sample()\n",
        "    log_prob = dist.log_prob(action)\n",
        "    states.append(state)\n",
        "    next_state, reward, terminated, truncated, _ = env.step(action.item())\n",
        "\n",
        "    log_probs.append(log_prob)\n",
        "    rewards.append(reward)\n",
        "    state = next_state\n",
        "    if terminated or truncated:\n",
        "      break\n",
        "  return states, log_probs, rewards"
      ],
      "metadata": {
        "id": "sTPfx8DsiE5Y"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch._C import Value\n",
        "import numpy as np\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "env = gym.make(\"CartPole-v1\")\n",
        "value_model = ValueNetwork()\n",
        "model = PolicyNetwork()\n",
        "policy_opt = optim.Adam(model.parameters() , lr = 1e-2)\n",
        "value_opt = optim.Adam(value_model.parameters() , lr = 1e-3)\n",
        "gamma = 0.99\n",
        "\n",
        "episode_returns = []\n",
        "\n",
        "\n",
        "for ep in range(1000) :\n",
        "  states, log_probs, rewards = run_episode_with_states(env, model, max_steps = 500)\n",
        "\n",
        "  returns = get_expected_return(rewards, gamma, standardize = True)\n",
        "  log_probs = torch.stack(log_probs)\n",
        "  values = value_model(torch.tensor(np.array(states), dtype=torch.float32))\n",
        "  advantages = returns - values.detach()\n",
        "\n",
        "  loss = -(log_probs * advantages).sum() + 0.5 * (values - returns).pow(2).sum()\n",
        "\n",
        "  policy_opt.zero_grad()\n",
        "  value_opt.zero_grad()\n",
        "  loss.backward()\n",
        "  policy_opt.step()\n",
        "  value_opt.step()\n",
        "\n",
        "  ep_ret = float(sum(rewards))\n",
        "  episode_returns.append(ep_ret)\n",
        "  avg100 = np.mean(episode_returns[-100:])\n",
        "  if (ep + 1) % 10 == 0:\n",
        "    print(f\"ep {ep+1:4d} | return {ep_ret:6.1f} | avg100 {avg100:6.1f} | loss {loss.item():8.3f}\")\n",
        "\n",
        "  if avg100 >= 475:\n",
        "    print(\"Solved CartPole-v1.\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atixrPSx6b4D",
        "outputId": "415ea63b-c3cb-483c-eaf4-2963ed9c0306"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep   10 | return   27.0 | avg100   23.3 | loss   15.686\n",
            "ep   20 | return   57.0 | avg100   27.2 | loss   32.612\n",
            "ep   30 | return   54.0 | avg100   33.2 | loss   26.165\n",
            "ep   40 | return   61.0 | avg100   34.1 | loss   29.405\n",
            "ep   50 | return  157.0 | avg100   40.5 | loss   74.093\n",
            "ep   60 | return   73.0 | avg100   54.0 | loss   29.636\n",
            "ep   70 | return  232.0 | avg100   63.1 | loss  118.291\n",
            "ep   80 | return  500.0 | avg100  103.2 | loss  207.547\n",
            "ep   90 | return  335.0 | avg100  143.6 | loss   80.308\n",
            "ep  100 | return  500.0 | avg100  168.2 | loss  111.555\n",
            "ep  110 | return  500.0 | avg100  215.9 | loss  209.530\n",
            "ep  120 | return  194.0 | avg100  253.6 | loss   72.549\n",
            "ep  130 | return  246.0 | avg100  265.0 | loss   59.902\n",
            "ep  140 | return   81.0 | avg100  293.1 | loss   31.792\n",
            "ep  150 | return  411.0 | avg100  313.6 | loss  165.892\n",
            "ep  160 | return  500.0 | avg100  351.5 | loss  216.774\n",
            "ep  170 | return  500.0 | avg100  389.7 | loss  215.924\n",
            "ep  180 | return  500.0 | avg100  401.1 | loss  230.595\n",
            "ep  190 | return  500.0 | avg100  404.5 | loss  322.447\n",
            "ep  200 | return  500.0 | avg100  415.5 | loss  241.874\n",
            "ep  210 | return  500.0 | avg100  415.5 | loss  225.966\n",
            "ep  220 | return  500.0 | avg100  424.7 | loss  210.327\n",
            "ep  230 | return  500.0 | avg100  458.8 | loss  200.205\n",
            "ep  240 | return  500.0 | avg100  472.9 | loss  204.633\n",
            "Solved CartPole-v1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Actor critic"
      ],
      "metadata": {
        "id": "4yngK_f1iFYm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XKy51_0wiGW6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}