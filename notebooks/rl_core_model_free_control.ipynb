{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "veFoA3PdEBuF"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Tuple, Dict, Optional\n",
        "import random\n",
        "import math\n",
        "\n",
        "Action = Tuple[int, int]\n",
        "State = Tuple[int, int, int, int]\n",
        "\n",
        "ACTIONS: List[Action] = [(dr, dc) for dr in (-1, 0, 1) for dc in (-1, 0, 1)]\n",
        "\n",
        "@dataclass\n",
        "class RacetrackSpec:\n",
        "  v_max: int = 5\n",
        "  slip_prob: float = 0.0\n",
        "  crash_reward: int = -5\n",
        "  step_reward: int = -1\n",
        "  seed: Optional[int] = None\n",
        "\n",
        "\n",
        "class RacetrackEnv:\n",
        "  def __init__(self,\n",
        "               grid, spec: RacetrackSpec = RacetrackSpec()):\n",
        "    self.grid = [list(row) for row in grid]\n",
        "\n",
        "    self.H = len(self.grid)\n",
        "\n",
        "    self.W = len(self.grid[0]) if self.H > 0 else 0\n",
        "\n",
        "    assert all(len(row) == self.W for row in self.grid), \"Grid must be rectangular.\"\n",
        "\n",
        "    self.spec = spec\n",
        "    self.rng = random.Random(spec.seed)\n",
        "\n",
        "    self.start_cells = [(r, c) for r in range(self.H) for c in range(self.W) if self.grid[r][c] == 'S']\n",
        "    self.finish_cells = {(r, c) for r in range(self.H) for c in range(self.W) if self.grid[r][c] == 'F'}\n",
        "\n",
        "    assert len(self.start_cells) > 0, \"Grid must contain at least one 'S' start cell.\"\n",
        "    assert len(self.finish_cells) > 0, \"Grid must contain at least one 'F' finish cell.\"\n",
        "    self.track_cells = {(r, c) for r in range(self.H) for c in range(self.W)\n",
        "                            if self.grid[r][c] in ('.', 'S', 'F')}\n",
        "\n",
        "    self.state: Optional[State] = None\n",
        "  def reset(self) -> State:\n",
        "    r, c = self.rng.choice(self.start_cells)\n",
        "    # Common choice: start with zero velocity (but must not be both zero per rules).\n",
        "    # We'll start at (0,1) or (1,0) randomly to satisfy \"cannot both be zero\".\n",
        "    if self.rng.random() < 0.5:\n",
        "        vr, vc = 0, 1\n",
        "    else:\n",
        "        vr, vc = 1, 0\n",
        "    self.state = (r, c, vr, vc)\n",
        "    return self.state\n",
        "\n",
        "  def in_bounds(self, r: int, c: int) -> bool:\n",
        "    return 0 <= r < self.H and 0 <= c < self.W\n",
        "\n",
        "  def is_track(self, r: int, c: int) -> bool:\n",
        "    return (r, c) in self.track_cells\n",
        "\n",
        "  def is_finish(self, r: int, c: int) -> bool:\n",
        "    return (r, c) in self.finish_cells\n",
        "  def clip_velocity(self, vr: int, vc: int) -> Tuple[int, int]:\n",
        "    vr = max(0, min(self.spec.v_max - 1, vr))\n",
        "    vc = max(0, min(self.spec.v_max - 1, vc))\n",
        "    if vr == 0 and vc == 0:\n",
        "\n",
        "        if self.rng.random() < 0.5:\n",
        "            vc = 1\n",
        "        else:\n",
        "            vr = 1\n",
        "    return vr, vc\n",
        "\n",
        "  def bresenham_cells(self, r0: int, c0: int, r1: int, c1: int) -> List[Tuple[int, int]]:\n",
        "    \"\"\"\n",
        "    Cells traversed by the line segment from (r0,c0) to (r1,c1), inclusive.\n",
        "    Using integer grid stepping so we detect wall/finish crossing, not just landing.\n",
        "    \"\"\"\n",
        "    cells = []\n",
        "    dr = abs(r1 - r0)\n",
        "    dc = abs(c1 - c0)\n",
        "    sr = 1 if r1 >= r0 else -1\n",
        "    sc = 1 if c1 >= c0 else -1\n",
        "\n",
        "    r, c = r0, c0\n",
        "    cells.append((r, c))\n",
        "\n",
        "    if dc == 0 and dr == 0:\n",
        "        return cells\n",
        "\n",
        "    if dc > dr:\n",
        "        err = dc / 2.0\n",
        "        while c != c1:\n",
        "            c += sc\n",
        "            err -= dr\n",
        "            if err < 0:\n",
        "                r += sr\n",
        "                err += dc\n",
        "            cells.append((r, c))\n",
        "    else:\n",
        "        err = dr / 2.0\n",
        "        while r != r1:\n",
        "            r += sr\n",
        "            err -= dc\n",
        "            if err < 0:\n",
        "                c += sc\n",
        "                err += dr\n",
        "            cells.append((r, c))\n",
        "\n",
        "    return cells\n",
        "\n",
        "  def apply_slip(self, r: int, c: int) -> Tuple[int, int]:\n",
        "    \"\"\"\n",
        "    With probability slip_prob, displace forward (down) or right by 1 extra cell.\n",
        "    \"\"\"\n",
        "    if self.rng.random() >= self.spec.slip_prob:\n",
        "        return r, c\n",
        "    # \"forward or to the right\" for right turns. forward means increasing row.\n",
        "    if self.rng.random() < 0.5:\n",
        "        return r - 1, c\n",
        "    else:\n",
        "        return r, c + 1\n",
        "\n",
        "\n",
        "  def step(self, action: Action) -> Tuple[State, int, bool, Dict]:\n",
        "        assert self.state is not None, \"Call reset() first.\"\n",
        "        r, c, vr, vc = self.state\n",
        "        dvr, dvc = action\n",
        "        assert (dvr, dvc) in ACTIONS, \"Invalid action.\"\n",
        "\n",
        "        # Update and clip velocity\n",
        "        nvr, nvc = self.clip_velocity(vr + dvr, vc + dvc)\n",
        "\n",
        "        # Proposed move by velocity\n",
        "        r2, c2 = r - nvr, c + nvc\n",
        "\n",
        "\n",
        "        # Apply stochastic extra displacement\n",
        "        r3, c3 = self.apply_slip(r2, c2)\n",
        "\n",
        "        path = self.bresenham_cells(r, c, r3, c3)\n",
        "\n",
        "        last_valid = (r, c)\n",
        "\n",
        "        for (rr, cc) in path[1:]:\n",
        "            # out of bounds or off-track => crash attempt\n",
        "            if not self.in_bounds(rr, cc) or not self.is_track(rr, cc):\n",
        "                # stay at last valid on-track cell\n",
        "                sr, sc = self.rng.choice(self.start_cells)\n",
        "                # reset velocity to small nonzero\n",
        "                if self.rng.random() < 0.5:\n",
        "                    nvr, nvc = 1, 0\n",
        "                else:\n",
        "                    nvr, nvc = 0, 1\n",
        "                self.state = (sr, sc, nvr, nvc)\n",
        "                return self.state, self.spec.crash_reward, False, {\"event\": \"crash\"}\n",
        "\n",
        "            # on track\n",
        "            last_valid = (rr, cc)\n",
        "\n",
        "            # finish crossing\n",
        "            if self.is_finish(rr, cc):\n",
        "                self.state = (rr, cc, nvr, nvc)\n",
        "                return self.state, self.spec.step_reward, True, {\"event\": \"finish\"}\n",
        "\n",
        "        # Normal on-track step (no finish, no crash)\n",
        "        self.state = (r3, c3, nvr, nvc)\n",
        "        return self.state, self.spec.step_reward, False, {\"event\": \"move\"}\n",
        "\n",
        "  def render(self, state: Optional[State] = None) -> str:\n",
        "    if state is None:\n",
        "        state = self.state\n",
        "    if state is None:\n",
        "        return \"\\n\".join(\"\".join(row) for row in self.grid)\n",
        "\n",
        "    r, c, vr, vc = state\n",
        "    out = [row[:] for row in self.grid]\n",
        "    out[r][c] = 'A'\n",
        "    return \"\\n\".join(\"\".join(row) for row in out)\n",
        "def make_example_track() -> List[str]:\n",
        "    \"\"\"\n",
        "    A simple right-turn track you can replace with your own.\n",
        "    '#' walls, '.' track, S start line, F finish line\n",
        "    \"\"\"\n",
        "    return [\n",
        "        \"####################\",\n",
        "        \"###########.....FFFF\",\n",
        "        \"###########.....FFFF\",\n",
        "        \"###########.....FFFF\",\n",
        "        \"###########.........\",\n",
        "        \"###########.........\",\n",
        "        \"#######.............\",\n",
        "        \"#######.............\",\n",
        "        \"SSSSSS..............\",\n",
        "        \"SSSSSS..............\",\n",
        "        \"####################\",\n",
        "    ]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = RacetrackEnv(make_example_track(), RacetrackSpec(seed =3))\n",
        "s = env.reset()\n",
        "print(env.render())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EB1jAknAG6jW",
        "outputId": "302d7acb-d332-4d0d-eb59-a5e2dbaa9bc3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSSASS..............\n",
            "SSSSSS..............\n",
            "####################\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(10):\n",
        "  a = random.choice(ACTIONS)\n",
        "  s, r, done, info = env.step(a)\n",
        "  print(\"\\n\", info, \"reward:\", r, \"state:\", s)\n",
        "  print(env.render())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lo1gcAbEHM1K",
        "outputId": "80ff6f19-3647-46b3-f621-9036113f59a7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " {'event': 'crash'} reward: -5 state: (9, 3, 1, 0)\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSSSSS..............\n",
            "SSSASS..............\n",
            "####################\n",
            "\n",
            " {'event': 'move'} reward: -1 state: (8, 3, 1, 0)\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSSASS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            " {'event': 'crash'} reward: -5 state: (9, 1, 1, 0)\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSSSSS..............\n",
            "SASSSS..............\n",
            "####################\n",
            "\n",
            " {'event': 'move'} reward: -1 state: (8, 1, 1, 0)\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SASSSS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            " {'event': 'move'} reward: -1 state: (8, 2, 0, 1)\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSASSS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            " {'event': 'move'} reward: -1 state: (8, 3, 0, 1)\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSSASS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            " {'event': 'move'} reward: -1 state: (8, 5, 0, 2)\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSSSSA..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            " {'event': 'move'} reward: -1 state: (8, 8, 0, 3)\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSSSSS..A...........\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            " {'event': 'move'} reward: -1 state: (8, 11, 0, 3)\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSSSSS.....A........\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            " {'event': 'move'} reward: -1 state: (8, 14, 0, 3)\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSSSSS........A.....\n",
            "SSSSSS..............\n",
            "####################\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Common helpers"
      ],
      "metadata": {
        "id": "ULaQPoqlKKIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import random\n",
        "\n",
        "def eps_greedy_action(Q, s, epsilon, rng: random.Random) :\n",
        "  if rng.random() < epsilon :\n",
        "    return rng.randrange(9)\n",
        "\n",
        "  qs = Q[s]\n",
        "  best = max(range(9) , key = lambda a: qs[a])\n",
        "  return best\n",
        "\n",
        "def init_Q() :\n",
        "  return defaultdict(lambda : [0.0] * 9 )"
      ],
      "metadata": {
        "id": "V7EYtlwrHUOt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Monte Carlo Control (first visit)"
      ],
      "metadata": {
        "id": "QeScZ8hhKrQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mc_control (env, episodes = 200_000,\n",
        "                gamma = 1.0, epsilon = 0.1, seed = 0, max_steps = 10_000) :\n",
        "  rng = random.Random(seed)\n",
        "  Q = init_Q()\n",
        "\n",
        "  returns_sum = defaultdict(lambda : [0.0] * 9 )\n",
        "  returns_cnt = defaultdict(lambda : [0] * 9 )\n",
        "\n",
        "  for ep in range(episodes) :\n",
        "    s = env.reset()\n",
        "    episode = []\n",
        "    done = False\n",
        "\n",
        "    for t in range(max_steps) :\n",
        "      a = eps_greedy_action(Q, s, epsilon, rng)\n",
        "      s2, r, done, info = env.step(ACTIONS[a])\n",
        "      episode.append((s, a, r) )\n",
        "\n",
        "      s = s2\n",
        "      if done :\n",
        "        break\n",
        "    G = 0.0\n",
        "\n",
        "    seen  = set()\n",
        "    for (s, a, r) in reversed(episode):\n",
        "      G = gamma* G + r\n",
        "      if (s, a) in seen:\n",
        "        continue\n",
        "      seen.add((s, a))\n",
        "\n",
        "      returns_sum[s][a] += G\n",
        "      returns_cnt[s][a] += 1\n",
        "\n",
        "      Q[s][a] = returns_sum[s][a] / returns_cnt[s][a]\n",
        "  return Q\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "c3dJlc3HKdIk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TD Control (SARSA)"
      ],
      "metadata": {
        "id": "AA_64ZUrL0uE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sarsa_control(env, episodes = 200_000, alpha = 0.1, gamma = 1.0, epsilon = 0.1, seed = 0, max_steps = 10_000):\n",
        "  rng = random.Random(seed)\n",
        "\n",
        "  Q = init_Q()\n",
        "\n",
        "  for ep in range(episodes) :\n",
        "    s = env.reset()\n",
        "    a = eps_greedy_action(Q, s, epsilon, rng)\n",
        "    done = False\n",
        "\n",
        "    for t in range(max_steps):\n",
        "      s2, r, done, info = env.step(ACTIONS[a])\n",
        "      if done:\n",
        "        Q[s][a] += alpha * (r- Q[s][a])\n",
        "        break\n",
        "      a2 = eps_greedy_action(Q, s2, epsilon, rng)\n",
        "      Q[s][a] += alpha * (r + gamma * Q[s2][a2] - Q[s][a])\n",
        "      s = s2\n",
        "      a = a2\n",
        "  return Q"
      ],
      "metadata": {
        "id": "MIxYPQmULzpP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TD Control(Q Learning)"
      ],
      "metadata": {
        "id": "F1VYvYwVOWo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def q_learning_control(env, episodes = 200_000, alpha = 0.1, gamma = 1.0, epsilon = 0.1, seed= 0 , max_steps = 15_000):\n",
        "  rng = random.Random(seed)\n",
        "\n",
        "  Q = init_Q()\n",
        "  for episode in range(episodes):\n",
        "    s = env.reset()\n",
        "    a = eps_greedy_action(Q, s, epsilon, rng)\n",
        "    done = False\n",
        "    for t in range(max_steps):\n",
        "      s2, r, done, info = env.step(ACTIONS[a])\n",
        "      if done:\n",
        "        Q[s][a] += alpha * (r- Q[s][a])\n",
        "        break\n",
        "      a2 = eps_greedy_action(Q, s2, epsilon, rng)\n",
        "      Q[s][a] += alpha * (r + gamma * max(Q[s2]) - Q[s][a])\n",
        "      s = s2\n",
        "      a = a2\n",
        "  return Q"
      ],
      "metadata": {
        "id": "rMctxifJOWN6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract greedy policies and print tracjectories"
      ],
      "metadata": {
        "id": "gru9HFybMavr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def greedy_policy(Q, s):\n",
        "  qs = Q[s]\n",
        "  return max(range(9), key = lambda a: qs[a])\n",
        "\n",
        "def rollout(env, Q, start_state = None, max_steps = 500):\n",
        "  if start_state is None:\n",
        "    s = env.reset()\n",
        "  else:\n",
        "    env.state = start_state\n",
        "    s = start_state\n",
        "  traj = [s]\n",
        "  total = 0\n",
        "  for _ in range(max_steps) :\n",
        "    a = greedy_policy(Q, s)\n",
        "    s, r, done, info = env.step(ACTIONS[a])\n",
        "    total += r\n",
        "    traj.append(s)\n",
        "    if done:\n",
        "      break\n",
        "  return traj, total\n",
        "def show_trajectory_on_grid(env, traj):\n",
        "  # just render successive positions\n",
        "  frames = []\n",
        "  for s in traj:\n",
        "      frames.append(env.render(s))\n",
        "  return \"\\n\\n\".join(frames)\n"
      ],
      "metadata": {
        "id": "-5PU8TQUMZHg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid = make_example_track()\n",
        "env = RacetrackEnv(grid, RacetrackSpec(seed = 0))"
      ],
      "metadata": {
        "id": "zgtf5RwoM-ic"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "Q_mc = mc_control(env, episodes = 50_000, epsilon = 0.2, seed = 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIp1kRUKNEDM",
        "outputId": "669dd0d4-4dec-4000-afe7-3c26d3092b1d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.29 s, sys: 2.31 ms, total: 2.29 s\n",
            "Wall time: 2.29 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = RacetrackEnv(grid, RacetrackSpec(seed=32))\n",
        "for i in range(3):\n",
        "  traj, ret = rollout(env, Q_mc, max_steps=200)\n",
        "  # ok, steps, ret = rollout(env, Q_td, 2000)\n",
        "  print(\"Trajectory\", i, \"return:\", ret, \"len:\", len(traj))\n",
        "  print(show_trajectory_on_grid(env, traj[:10]))  # first 10 frames only\n",
        "\n",
        "  # print(\"finished?\", ok, \"steps\", steps, \"return\", ret)\n",
        "  print(\"----\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdDK3ma-fDHD",
        "outputId": "1471a11f-8fe0-4d0a-90be-4c3dab4aff48"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trajectory 0 return: -7 len: 8\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SASSSS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSASSS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSSSAS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSSSSSA.............\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSSSSS...A..........\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######....A........\n",
            "SSSSSS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########...A.....\n",
            "#######.............\n",
            "#######.............\n",
            "SSSSSS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....AFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSSSSS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "----\n",
            "Trajectory 1 return: -13 len: 10\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "ASSSSS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSSSSS..............\n",
            "SASSSS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSSSSS..............\n",
            "SSASSS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSSSSS..............\n",
            "SSSASS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSSSSS..............\n",
            "SSSSAS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSSSSS..............\n",
            "SSSSSSA.............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSSSSS.A............\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######..A..........\n",
            "SSSSSS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.A.......\n",
            "#######.............\n",
            "#######.............\n",
            "SSSSSS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....AFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSSSSS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "----\n",
            "Trajectory 2 return: -6 len: 7\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SASSSS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSSASS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSSSSA..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######A............\n",
            "SSSSSS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######...A.........\n",
            "#######.............\n",
            "SSSSSS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########...A.....\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSSSSS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....AFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSSSSS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "----\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "env = RacetrackEnv(grid, RacetrackSpec(seed=0))\n",
        "Q_td = sarsa_control(env, episodes=50_000, alpha=0.2, epsilon=0.2, seed=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhcfwInLNIz5",
        "outputId": "705240f8-a1dd-41f3-affc-dd65681d755e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.67 s, sys: 2.11 ms, total: 1.67 s\n",
            "Wall time: 1.67 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = RacetrackEnv(grid, RacetrackSpec(seed=123))\n",
        "for i in range(3):\n",
        "  traj, ret = rollout(env, Q_td, max_steps=200)\n",
        "  # ok, steps, ret = rollout(env, Q_td, 2000)\n",
        "  print(\"Trajectory\", i, \"return:\", ret, \"len:\", len(traj))\n",
        "  print(show_trajectory_on_grid(env, traj[:10]))  # first 10 frames only\n",
        "\n",
        "  # print(\"finished?\", ok, \"steps\", steps, \"return\", ret)\n",
        "  print(\"----\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZL7FjvcNNua",
        "outputId": "8cbbaf22-82cc-491f-8aec-18244890da41"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trajectory 0 return: -5 len: 6\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "ASSSSS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSASSS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSSSSA..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######..A..........\n",
            "SSSSSS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########..A......\n",
            "#######.............\n",
            "#######.............\n",
            "SSSSSS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....AFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSSSSS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "----\n",
            "Trajectory 1 return: -5 len: 6\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSSSSS..............\n",
            "SSASSS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSSSSS..............\n",
            "SSSSAS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSSSSS.A............\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######...A.........\n",
            "SSSSSS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########...A.....\n",
            "#######.............\n",
            "#######.............\n",
            "SSSSSS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FAFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSSSSS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "----\n",
            "Trajectory 2 return: -6 len: 7\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "ASSSSS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SASSSS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSSASS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSSSSSA.............\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######..A..........\n",
            "SSSSSS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########..A......\n",
            "#######.............\n",
            "#######.............\n",
            "SSSSSS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....AFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSSSSS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "----\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "env = RacetrackEnv(grid, RacetrackSpec(seed=0))\n",
        "Q_tdq = q_learning_control(env, episodes=50_000, alpha=0.2, epsilon=0.2, seed=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bX1KslffJus",
        "outputId": "5b0baac4-0101-4a69-81dc-7107a14fff60"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.94 s, sys: 1.96 ms, total: 1.94 s\n",
            "Wall time: 1.95 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = RacetrackEnv(grid, RacetrackSpec(seed=123))\n",
        "for i in range(3):\n",
        "  traj, ret = rollout(env, Q_tdq, max_steps=200)\n",
        "  # ok, steps, ret = rollout(env, Q_td, 2000)\n",
        "  print(\"Trajectory\", i, \"return:\", ret, \"len:\", len(traj))\n",
        "  print(show_trajectory_on_grid(env, traj[:10]))  # first 10 frames only\n",
        "\n",
        "  # print(\"finished?\", ok, \"steps\", steps, \"return\", ret)\n",
        "  print(\"----\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_I8OMuL_fNGE",
        "outputId": "d808d44e-8d6a-49f9-d0d0-4a7245091f69"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trajectory 0 return: -5 len: 6\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "ASSSSS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSASSS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSSSSA..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.A...........\n",
            "SSSSSS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.A.......\n",
            "#######.............\n",
            "#######.............\n",
            "SSSSSS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....AFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSSSSS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "----\n",
            "Trajectory 1 return: -5 len: 6\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSSSSS..............\n",
            "SSASSS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSSSSS..............\n",
            "SSSSAS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSSSSS.A............\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######....A........\n",
            "#######.............\n",
            "SSSSSS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########....A....\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSSSSS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....AFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSSSSS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "----\n",
            "Trajectory 2 return: -6 len: 7\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "ASSSSS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SASSSS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSSASS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSSSSA..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.A...........\n",
            "SSSSSS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.A.......\n",
            "#######.............\n",
            "#######.............\n",
            "SSSSSS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....AFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSSSSS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "----\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deep Q Networks"
      ],
      "metadata": {
        "id": "NHU-27MpTPj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from collections import deque\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def encode_state(env, s):\n",
        "    r, c, vr, vc = s\n",
        "    return np.array([\n",
        "        r / (env.H - 1),\n",
        "        c / (env.W - 1),\n",
        "        vr / (env.spec.v_max - 1),\n",
        "        vc / (env.spec.v_max - 1),\n",
        "    ], dtype=np.float32)\n",
        "\n",
        "class QNet(nn.Module):\n",
        "    def __init__(self, in_dim=4, out_dim=9):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, out_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class ReplayBuffer:\n",
        "    def __init__(self, capacity=200_000):\n",
        "        self.buf = deque(maxlen=capacity)\n",
        "\n",
        "    def push(self, s, a, r, s2, done):\n",
        "        self.buf.append((s, a, r, s2, done))\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        batch = random.sample(self.buf, batch_size)\n",
        "        s, a, r, s2, done = zip(*batch)\n",
        "        return np.stack(s), np.array(a), np.array(r, dtype=np.float32), np.stack(s2), np.array(done, dtype=np.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.buf)\n",
        "\n",
        "@torch.no_grad()\n",
        "def select_action(qnet, state_vec, epsilon):\n",
        "    if random.random() < epsilon:\n",
        "        return random.randrange(9)\n",
        "    x = torch.from_numpy(state_vec).unsqueeze(0).to(device)\n",
        "    q = qnet(x)[0]\n",
        "    return int(torch.argmax(q).item())\n",
        "\n",
        "def dqn_train(\n",
        "    env,\n",
        "    episodes=50_000,\n",
        "    gamma=1.0,\n",
        "    lr=1e-3,\n",
        "    batch_size=256,\n",
        "    buffer_size=200_000,\n",
        "    min_buffer=5_000,\n",
        "    target_update_every=1000,   # steps\n",
        "    epsilon_start=1.0,\n",
        "    epsilon_end=0.05,\n",
        "    epsilon_decay_steps=200_000,\n",
        "    max_steps_per_ep=10_000,\n",
        "    seed=0\n",
        "):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    qnet = QNet().to(device)\n",
        "    target = QNet().to(device)\n",
        "    target.load_state_dict(qnet.state_dict())\n",
        "    target.eval()\n",
        "\n",
        "    opt = optim.Adam(qnet.parameters(), lr=lr)\n",
        "    replay = ReplayBuffer(buffer_size)\n",
        "\n",
        "    steps = 0\n",
        "\n",
        "    def epsilon_by_step(t):\n",
        "        if t >= epsilon_decay_steps:\n",
        "            return epsilon_end\n",
        "        frac = t / epsilon_decay_steps\n",
        "        return epsilon_start + frac * (epsilon_end - epsilon_start)\n",
        "\n",
        "    for ep in range(episodes):\n",
        "        s = env.reset()\n",
        "        sv = encode_state(env, s)\n",
        "        ep_return = 0.0\n",
        "\n",
        "        for t in range(max_steps_per_ep):\n",
        "            eps = epsilon_by_step(steps)\n",
        "            a = select_action(qnet, sv, eps)\n",
        "\n",
        "            s2, r, done, info = env.step(ACTIONS[a])\n",
        "            sv2 = encode_state(env, s2)\n",
        "\n",
        "            replay.push(sv, a, r, sv2, done)\n",
        "\n",
        "            sv = sv2\n",
        "            ep_return += r\n",
        "            steps += 1\n",
        "\n",
        "            # Learn\n",
        "            if len(replay) >= min_buffer:\n",
        "                bs, ba, br, bs2, bdone = replay.sample(batch_size)\n",
        "\n",
        "                bs_t   = torch.from_numpy(bs).to(device)\n",
        "                ba_t   = torch.from_numpy(ba).long().to(device)\n",
        "                br_t   = torch.from_numpy(br).to(device)\n",
        "                bs2_t  = torch.from_numpy(bs2).to(device)\n",
        "                done_t = torch.from_numpy(bdone).to(device)\n",
        "\n",
        "                q_sa = qnet(bs_t).gather(1, ba_t.view(-1, 1)).squeeze(1)\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    # Vanilla DQN target\n",
        "                    max_q_s2 = target(bs2_t).max(dim=1).values\n",
        "                    y = br_t + gamma * (1.0 - done_t) * max_q_s2\n",
        "\n",
        "                loss = nn.MSELoss()(q_sa, y)\n",
        "\n",
        "                opt.zero_grad()\n",
        "                loss.backward()\n",
        "                nn.utils.clip_grad_norm_(qnet.parameters(), 10.0)\n",
        "                opt.step()\n",
        "\n",
        "                # Target network update\n",
        "                if steps % target_update_every == 0:\n",
        "                    target.load_state_dict(qnet.state_dict())\n",
        "\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "        if (ep + 1) % 200 == 0:\n",
        "            print(f\"ep {ep+1}  return {ep_return:.1f}  eps {epsilon_by_step(steps):.3f}  buffer {len(replay)}\")\n",
        "\n",
        "    return qnet\n"
      ],
      "metadata": {
        "id": "SDc95JqNTRBa"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "grid = make_example_track()\n",
        "env = RacetrackEnv(grid, RacetrackSpec(seed=0))\n",
        "qnet = dqn_train(env, episodes=20_000)\n",
        "\n",
        "# greedy rollout\n",
        "env = RacetrackEnv(grid, RacetrackSpec(seed=123))\n",
        "s = env.reset()\n",
        "sv = encode_state(env, s)\n",
        "for _ in range(60):\n",
        "    a = select_action(qnet, sv, epsilon=0.0)\n",
        "    s, r, done, info = env.step(ACTIONS[a])\n",
        "    sv = encode_state(env, s)\n",
        "    print(info, r, s)\n",
        "    print(env.render())\n",
        "    if done:\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AH1tnWz3TRo7",
        "outputId": "bbeb1eef-63e3-4f1b-a054-af59ed80fa87"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 200  return -178.0  eps 0.946  buffer 11426\n",
            "ep 400  return -45.0  eps 0.908  buffer 19283\n",
            "ep 600  return -33.0  eps 0.881  buffer 25108\n",
            "ep 800  return -82.0  eps 0.855  buffer 30541\n",
            "ep 1000  return -56.0  eps 0.832  buffer 35280\n",
            "ep 1200  return -88.0  eps 0.810  buffer 39901\n",
            "ep 1400  return -6.0  eps 0.791  buffer 43985\n",
            "ep 1600  return -13.0  eps 0.773  buffer 47731\n",
            "ep 1800  return -31.0  eps 0.755  buffer 51545\n",
            "ep 2000  return -25.0  eps 0.739  buffer 55034\n",
            "ep 2200  return -29.0  eps 0.722  buffer 58569\n",
            "ep 2400  return -13.0  eps 0.707  buffer 61697\n",
            "ep 2600  return -15.0  eps 0.693  buffer 64725\n",
            "ep 2800  return -10.0  eps 0.678  buffer 67685\n",
            "ep 3000  return -20.0  eps 0.665  buffer 70616\n",
            "ep 3200  return -68.0  eps 0.652  buffer 73254\n",
            "ep 3400  return -10.0  eps 0.640  buffer 75815\n",
            "ep 3600  return -7.0  eps 0.629  buffer 78160\n",
            "ep 3800  return -15.0  eps 0.616  buffer 80812\n",
            "ep 4000  return -15.0  eps 0.605  buffer 83164\n",
            "ep 4200  return -6.0  eps 0.593  buffer 85590\n",
            "ep 4400  return -5.0  eps 0.582  buffer 87935\n",
            "ep 4600  return -5.0  eps 0.572  buffer 90070\n",
            "ep 4800  return -5.0  eps 0.561  buffer 92359\n",
            "ep 5000  return -6.0  eps 0.550  buffer 94655\n",
            "ep 5200  return -12.0  eps 0.540  buffer 96795\n",
            "ep 5400  return -8.0  eps 0.530  buffer 98943\n",
            "ep 5600  return -49.0  eps 0.520  buffer 101019\n",
            "ep 5800  return -17.0  eps 0.511  buffer 103002\n",
            "ep 6000  return -5.0  eps 0.501  buffer 105025\n",
            "ep 6200  return -24.0  eps 0.492  buffer 107011\n",
            "ep 6400  return -5.0  eps 0.482  buffer 109078\n",
            "ep 6600  return -17.0  eps 0.473  buffer 110994\n",
            "ep 6800  return -12.0  eps 0.464  buffer 112847\n",
            "ep 7000  return -8.0  eps 0.455  buffer 114656\n",
            "ep 7200  return -4.0  eps 0.447  buffer 116458\n",
            "ep 7400  return -23.0  eps 0.438  buffer 118247\n",
            "ep 7600  return -8.0  eps 0.430  buffer 119922\n",
            "ep 7800  return -4.0  eps 0.422  buffer 121599\n",
            "ep 8000  return -8.0  eps 0.414  buffer 123290\n",
            "ep 8200  return -21.0  eps 0.407  buffer 124942\n",
            "ep 8400  return -6.0  eps 0.399  buffer 126545\n",
            "ep 8600  return -6.0  eps 0.391  buffer 128253\n",
            "ep 8800  return -5.0  eps 0.383  buffer 129871\n",
            "ep 9000  return -6.0  eps 0.376  buffer 131405\n",
            "ep 9200  return -5.0  eps 0.368  buffer 132962\n",
            "ep 9400  return -5.0  eps 0.361  buffer 134478\n",
            "ep 9600  return -13.0  eps 0.354  buffer 135912\n",
            "ep 9800  return -7.0  eps 0.347  buffer 137470\n",
            "ep 10000  return -6.0  eps 0.340  buffer 138968\n",
            "ep 10200  return -6.0  eps 0.333  buffer 140494\n",
            "ep 10400  return -11.0  eps 0.325  buffer 142002\n",
            "ep 10600  return -6.0  eps 0.318  buffer 143478\n",
            "ep 10800  return -5.0  eps 0.312  buffer 144843\n",
            "ep 11000  return -5.0  eps 0.305  buffer 146320\n",
            "ep 11200  return -5.0  eps 0.299  buffer 147683\n",
            "ep 11400  return -22.0  eps 0.292  buffer 149129\n",
            "ep 11600  return -13.0  eps 0.285  buffer 150525\n",
            "ep 11800  return -8.0  eps 0.279  buffer 151839\n",
            "ep 12000  return -7.0  eps 0.272  buffer 153355\n",
            "ep 12200  return -5.0  eps 0.265  buffer 154708\n",
            "ep 12400  return -6.0  eps 0.259  buffer 156001\n",
            "ep 12600  return -5.0  eps 0.253  buffer 157291\n",
            "ep 12800  return -18.0  eps 0.247  buffer 158584\n",
            "ep 13000  return -5.0  eps 0.240  buffer 159935\n",
            "ep 13200  return -6.0  eps 0.234  buffer 161162\n",
            "ep 13400  return -26.0  eps 0.229  buffer 162418\n",
            "ep 13600  return -17.0  eps 0.222  buffer 163712\n",
            "ep 13800  return -5.0  eps 0.216  buffer 164948\n",
            "ep 14000  return -5.0  eps 0.211  buffer 166161\n",
            "ep 14200  return -5.0  eps 0.205  buffer 167349\n",
            "ep 14400  return -5.0  eps 0.199  buffer 168603\n",
            "ep 14600  return -5.0  eps 0.193  buffer 169829\n",
            "ep 14800  return -5.0  eps 0.188  buffer 170995\n",
            "ep 15000  return -5.0  eps 0.182  buffer 172173\n",
            "ep 15200  return -5.0  eps 0.176  buffer 173406\n",
            "ep 15400  return -6.0  eps 0.171  buffer 174607\n",
            "ep 15600  return -4.0  eps 0.165  buffer 175799\n",
            "ep 15800  return -5.0  eps 0.159  buffer 176967\n",
            "ep 16000  return -5.0  eps 0.154  buffer 178137\n",
            "ep 16200  return -5.0  eps 0.148  buffer 179272\n",
            "ep 16400  return -6.0  eps 0.143  buffer 180422\n",
            "ep 16600  return -5.0  eps 0.138  buffer 181535\n",
            "ep 16800  return -11.0  eps 0.132  buffer 182647\n",
            "ep 17000  return -5.0  eps 0.127  buffer 183743\n",
            "ep 17200  return -8.0  eps 0.122  buffer 184876\n",
            "ep 17400  return -5.0  eps 0.117  buffer 185999\n",
            "ep 17600  return -5.0  eps 0.111  buffer 187129\n",
            "ep 17800  return -6.0  eps 0.106  buffer 188267\n",
            "ep 18000  return -6.0  eps 0.101  buffer 189326\n",
            "ep 18200  return -4.0  eps 0.095  buffer 190428\n",
            "ep 18400  return -5.0  eps 0.090  buffer 191484\n",
            "ep 18600  return -5.0  eps 0.085  buffer 192587\n",
            "ep 18800  return -6.0  eps 0.080  buffer 193663\n",
            "ep 19000  return -5.0  eps 0.075  buffer 194702\n",
            "ep 19200  return -5.0  eps 0.070  buffer 195761\n",
            "ep 19400  return -5.0  eps 0.065  buffer 196798\n",
            "ep 19600  return -4.0  eps 0.060  buffer 197840\n",
            "ep 19800  return -4.0  eps 0.055  buffer 198881\n",
            "ep 20000  return -4.0  eps 0.050  buffer 199897\n",
            "{'event': 'move'} -1 (8, 2, 0, 2)\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSASSS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "{'event': 'move'} -1 (8, 5, 0, 3)\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSSSSA..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "{'event': 'move'} -1 (7, 9, 1, 4)\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######..A..........\n",
            "SSSSSS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "{'event': 'move'} -1 (5, 13, 2, 4)\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.........\n",
            "###########..A......\n",
            "#######.............\n",
            "#######.............\n",
            "SSSSSS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "{'event': 'finish'} -1 (3, 16, 3, 4)\n",
            "####################\n",
            "###########.....FFFF\n",
            "###########.....FFFF\n",
            "###########.....AFFF\n",
            "###########.........\n",
            "###########.........\n",
            "#######.............\n",
            "#######.............\n",
            "SSSSSS..............\n",
            "SSSSSS..............\n",
            "####################\n",
            "CPU times: user 12min 16s, sys: 6.92 s, total: 12min 23s\n",
            "Wall time: 12min 36s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zzm7Fd5FfpN6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}